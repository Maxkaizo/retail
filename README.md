
# üõí Predicci√≥n de Demanda en Retail

En este proyecto desarrollar√© un **pipeline de Machine Learning** para entrenar y evaluar modelos de predicci√≥n de demanda en un escenario de retail.  

La base del proyecto es el reto [Rohlik Sales Forecasting Challenge](https://www.kaggle.com/competitions/rohlik-sales-forecasting-challenge-v2/overview), cuyo objetivo consiste en **predecir las ventas diarias de productos seleccionados para un horizonte de 14 d√≠as**, utilizando datos hist√≥ricos de ventas, precios y calendario.

El proyecto sigue la metodolog√≠a [**CRISP-DM**](https://www.ibm.com/docs/es/spss-modeler/saas?topic=dm-crisp-help-overview), abordando cada etapa:  
1. **Definici√≥n del problema** y justificaci√≥n de impacto en el negocio.  
2. **An√°lisis exploratorio y preprocesamiento** de datos hist√≥ricos.  
3. **Modelado y evaluaci√≥n** con m√©tricas adecuadas (WMAE como principal).  
4. **Implementaci√≥n de un pipeline reproducible** con orquestaci√≥n y registro de modelos.  
5. **Documentaci√≥n y comunicaci√≥n de resultados**, incluyendo an√°lisis de errores y explicabilidad.  

La finalidad no es √∫nicamente construir un modelo predictivo, sino tambi√©n mostrar un flujo completo de *machine learning en producci√≥n local* usando herramientas de c√≥digo abierto, con buenas pr√°cticas que permitan escalar de manera estable a entornos productivos y **mostrar c√≥mo esta pr√°ctica puede convertirse en una herramienta que genere valor tangible para el negocio**.  

# üìå Definici√≥n del Problema y Objetivos

## Contexto
Rohlik es una empresa del sector *e-grocery* (supermercado en l√≠nea) que administra m√∫ltiples almacenes para surtir pedidos diarios.  
En este tipo de negocio, el reto de **predecir la demanda futura de productos** es crucial para:
- Optimizar inventarios.  
- Reducir desperdicios por caducidad.  
- Mejorar el nivel de servicio (evitar faltantes de stock).  

## Problema a resolver
Actualmente, la planificaci√≥n de inventarios se apoya en m√©todos heur√≠sticos y reglas de negocio (por ejemplo, promedios hist√≥ricos).  
Estos enfoques no capturan la complejidad de los patrones reales:
- Estacionalidad (alta demanda en fines de semana o feriados).  
- Promociones y descuentos.  
- Diferencias de comportamiento entre categor√≠as de productos.  
- Variabilidad entre almacenes.  

El problema central es entonces:  
**¬øC√≥mo construir un modelo de machine learning que pueda predecir de manera precisa las ventas diarias por SKU y almac√©n, minimizando errores en productos clave?**


## Objetivos del proyecto
De manera espec√≠fica, se busca:  

1. **Mejorar la planificaci√≥n de inventarios** mediante predicciones de ventas m√°s precisas, lo que reduce faltantes y desperdicio de producto.  
2. **Optimizar la operaci√≥n log√≠stica y de compras**, al proveer estimaciones confiables que faciliten la toma de decisiones en abastecimiento y distribuci√≥n.  
3. **Evaluar el impacto del uso de machine learning frente a enfoques tradicionales**, demostrando con m√©tricas claras la mejora alcanzada en la predicci√≥n de la demanda.  
4. **Implementar un pipeline reproducible** que sirva como punto de partida para incorporar pr√°cticas de ML en el negocio, permitiendo escalar y mejorar con el tiempo.  
5. **Facilitar la interpretaci√≥n de resultados** a trav√©s de an√°lisis de errores y explicabilidad, para que los hallazgos puedan integrarse en procesos de negocio y no queden como una ‚Äúcaja negra‚Äù.  


## Relevancia e impacto
- **Compras**: prever cantidades exactas y negociar con proveedores.  
- **Log√≠stica**: planear rutas de entrega y personal de surtido.  
- **Direcci√≥n comercial**: evaluar impacto de promociones y ajustar estrategia.  

El impacto potencial es una **reducci√≥n de costos operativos** y una **mejor experiencia del cliente final**.

Citando la descripci√≥n de la competencia:
"Por qu√© es importante?
Las predicciones precisas de ventas son cruciales para los procesos de planeaci√≥n, la cadena de suministro, la log√≠stica de entregas y la gesti√≥n de inventarios. Al optimizar los pron√≥sticos, podemos minimizar el desperdicio y hacer m√°s eficientes las operaciones, logrando que nuestros servicios de comercio electr√≥nico de comestibles sean m√°s sostenibles y eficaces."

## Acciones sin ML (baseline de negocio)

Antes de implementar un modelo de machine learning, existen diversas acciones que la empresa podr√≠a realizar para mejorar la planeaci√≥n de demanda:

- **M√©todos estad√≠sticos simples**: aplicar promedios m√≥viles o suavizaci√≥n exponencial para capturar tendencias b√°sicas.  
- **Referencias a d√≠as similares previos**: usar como predicci√≥n los valores de ventas del **d√≠a anterior**, la **semana anterior** o incluso el **mes anterior** (modelo ingenuo).  
- **Reglas de negocio**: ajustar inventarios en fechas especiales (ej. Navidad, vacaciones escolares, eventos locales).  
- **An√°lisis de hist√≥ricos**: revisar manualmente patrones de estacionalidad y detectar productos con mayor volatilidad o estacionalidad marcada.  
- **Segmentaci√≥n de productos**: identificar categor√≠as cr√≠ticas (ej. l√°cteos, panader√≠a, bebidas) y darles un tratamiento especial en las √≥rdenes de compra.  
- **Buffers de seguridad**: establecer inventario de seguridad para productos de alta rotaci√≥n o alta variabilidad en la demanda.  
- **Experiencia del personal**: muchas empresas recurren a la sensibilidad y conocimiento acumulado de compradores y planificadores de inventario; aunque no es un enfoque sistem√°tico, puede complementar los m√©todos anteriores.  

Estas acciones son relevantes porque forman un **baseline operativo**, contra el cual se podr√° comparar el valor a√±adido de un modelo de machine learning m√°s avanzado. 

## üìä Descripci√≥n del dataset

El dataset contiene informaci√≥n hist√≥rica de ventas de Rohlik para distintos productos e inventarios, junto con datos de calendario y contexto operacional.  
Las columnas principales son:  

### üìÇ Archivos

- **sales_train.csv** ‚Äì 
- **sales_test.csv** ‚Äì conjunto de prueba completo.  
- **inventory.csv** ‚Äì  
- **calendar.csv** ‚Äì 


### **sales_train.csv / sales_test.csv**
Conjuntos de entrenamiento y pruebas que contiene los datos hist√≥ricos de ventas para cada fecha e inventario, con las caracter√≠sticas descritas abajo.  
- **unique_id**: identificador √∫nico del inventario (producto en un almac√©n espec√≠fico).  
- **date**: fecha del registro.  
- **warehouse**: nombre del almac√©n.  
- **total_orders**: n√∫mero total de pedidos procesados por el almac√©n en esa fecha (variable de contexto compartida por todos los SKUs del almac√©n).  
- **sales**: volumen de ventas (en piezas o kg), ajustado por disponibilidad.  
- **sell_price_main**: precio de venta.  
- **availability**: proporci√≥n del d√≠a en que el inventario estuvo disponible (1 = todo el d√≠a).  
- **type_0_discount, type_1_discount, ‚Ä¶**: descuentos aplicados, expresados como porcentaje sobre el precio original.  

### **inventory.csv**
Informaci√≥n adicional sobre el inventario, como el producto (los mismos productos en diferentes almacenes comparten el mismo **product_unique_id** y nombre, pero tienen distinto **unique_id**). 
- **unique_id**: identificador √∫nico del inventario.  
- **product_unique_id**: identificador del producto (compartido entre almacenes).  
- **name**: nombre del producto.  
- **L1_category_name, L2_category_name, ‚Ä¶**: categor√≠as internas (m√°s granularidad a mayor n√∫mero).  
- **warehouse**: nombre del almac√©n.  

### **calendar.csv**
Calendario con datos sobre feriados o eventos espec√≠ficos de los almacenes. Algunas columnas ya est√°n incluidas en el conjunto de entrenamiento, pero este archivo incluye filas adicionales para fechas donde ciertos almacenes pudieron haber estado cerrados por feriado o domingo (y por tanto no aparecen en el train set).  
- **warehouse**: nombre del almac√©n.  
- **date**: fecha.  
- **holiday_name**: nombre del feriado (si aplica).  
- **holiday**: indicador binario de feriado.  
- **shops_closed**: indicador de cierre de tiendas.  
- **winter_school_holidays**: vacaciones de invierno escolares.  
- **school_holidays**: vacaciones escolares.  

### **test_weights.csv**
- **unique_id**: identificador √∫nico del inventario.  
- **weight**: peso utilizado para el c√°lculo de la m√©trica oficial (WMAE).  

---

## üöÄ Estrategia de despliegue propuesta

El despliegue se realizar√° de manera **local, reproducible y en batch**, lo que significa que:  

- **Entrenamiento**: se ejecutar√° bajo demanda utilizando datos hist√≥ricos, generando y registrando un modelo con sus m√©tricas.  
- **Inferencia**: el modelo entrenado producir√° predicciones para el siguiente d√≠a, simulando la llegada de datos nuevos.  
- **Evaluaci√≥n**: conforme se dispongan los valores reales, se comparar√°n contra las predicciones para calcular m√©tricas de desempe√±o.  

Este enfoque asegura un pipeline **ejecutable de principio a fin** y f√°cilmente repetible, cumpliendo los requisitos de la r√∫brica sin necesidad de desplegar un servicio de inferencia en l√≠nea.

## ‚öôÔ∏è Arquitectura de la Soluci√≥n

El proyecto se soporta en una **arquitectura local con contenedores**, que permite reproducir experimentos de manera confiable y almacenar resultados en la nube:

![alt text](image.png)

- **MLflow**: servidor de tracking y registry, configurado para guardar artefactos y modelos en un bucket de **Amazon S3**.  
- **Prefect 2.0**: servidor de orquestaci√≥n para gestionar la ejecuci√≥n de flujos de entrenamiento y validaci√≥n.  
- **Postgres**: base de datos para almacenar metadatos de MLflow y Prefect.  
- **Docker Compose**: define los servicios y redes internas, asegurando que todos los componentes se levanten de forma consistente.  
- **S3 bucket (`ml-codigo-facilito-2025`)**: almacena de manera centralizada los modelos y artefactos generados en cada run.  

Con esta configuraci√≥n:  
- Los experimentos se lanzan desde el entorno local (conda env `forecasting`).  
- MLflow recibe m√©tricas, par√°metros y artefactos.  
- Prefect registra y monitorea la ejecuci√≥n de los flujos.  
- Los modelos quedan versionados y disponibles para ser promovidos en el registry.  

La infraestructura ya est√° **funcional y accesible v√≠a UI** tanto para MLflow (`http://localhost:5000`) como para Prefect (`http://localhost:4200`).  

---

## üß™ Estrategia de Entrenamiento

Se desarroll√≥ una **libreta de entrenamiento inicial**, conectada al pipeline de tracking, que implementa la siguiente estrategia:

1. **Carga y filtrado de datos**  
   - Se utiliza el archivo enriquecido `sales_train_enriched.csv`.  
   - Para acelerar el desarrollo, se filtran √∫nicamente registros del a√±o **2023**.  
   - Se respeta la naturaleza temporal de los datos: los splits se hacen **cronol√≥gicamente** (80% entrenamiento, 20% validaci√≥n), evitando fuga de informaci√≥n del futuro.  

2. **Selecci√≥n de features y target**  
   - Target inicial: `sales_log`.  
   - Features seleccionadas: transformaciones logar√≠tmicas (`orders_log`, `price_log`) y variables derivadas como `max_discount`.  
   - Esto asegura estabilidad en la distribuci√≥n y reduce el sesgo en las m√©tricas.  

3. **Modelos considerados**  
   - **Baseline** con RandomForest, usando hiperpar√°metros b√°sicos.  
   - **LightGBM, XGBoost y CatBoost**, optimizados con **Hyperopt** sobre un espacio de hiperpar√°metros reducido (10‚Äì20 evaluaciones por modelo).  

4. **Registro en MLflow**  
   - Cada run se registra con par√°metros, m√©tricas (RMSE) y artefactos (modelo serializado).  
   - Los modelos quedan almacenados en S3 y versionados en el registry de MLflow, listos para ser comparados o promovidos.  

---

## ‚úÖ Estado Actual

- La infraestructura (MLflow + Prefect + Postgres + S3) est√° **levantada y validada**.  
- Se han corrido los primeros experimentos de prueba exitosamente, confirmando el flujo de tracking y almacenamiento en la nube.  
- La libreta de entrenamiento ya permite entrenar modelos base y optimizados, dejando listos los componentes para la siguiente etapa:  
  - Definir la lista final de features relevantes.  
  - Completar la comparativa de modelos.  
  - Documentar los resultados en el README y realizar un primer *submit* del proyecto.  
