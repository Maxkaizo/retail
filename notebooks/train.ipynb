{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ddd977",
   "metadata": {},
   "source": [
    "#  Entrenamiento y selección de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f8b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932efe8",
   "metadata": {},
   "source": [
    "## 1. Cargar dataset y filtrar 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8464f3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros totales 2023: 1239531\n",
      "Rango de fechas: 2023-01-01 00:00:00 → 2023-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"../data/sales_train_enriched.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Filtrar solo año 2023\n",
    "df = df[df[\"date\"].dt.year == 2023].copy()\n",
    "\n",
    "print(\"Registros totales 2023:\", len(df))\n",
    "print(\"Rango de fechas:\", df[\"date\"].min(), \"→\", df[\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55572238",
   "metadata": {},
   "source": [
    "## 2. Split temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318fe706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño entrenamiento: 991624\n",
      "Tamaño validación: 247907\n",
      "Última fecha train: 2023-10-21 00:00:00\n",
      "Primera fecha val: 2023-10-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por fecha (muy importante en series temporales)\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "# Split 80/20 cronológico\n",
    "split_idx = int(len(df) * 0.8)\n",
    "\n",
    "train = df.iloc[:split_idx]\n",
    "val   = df.iloc[split_idx:]\n",
    "\n",
    "# Definir X, y\n",
    "X_train = train.drop(columns=[\"sales\", \"date\"])\n",
    "y_train = train[\"sales\"]\n",
    "\n",
    "X_val = val.drop(columns=[\"sales\", \"date\"])\n",
    "y_val = val[\"sales\"]\n",
    "\n",
    "print(\"Tamaño entrenamiento:\", len(train))\n",
    "print(\"Tamaño validación:\", len(val))\n",
    "print(\"Última fecha train:\", train[\"date\"].max())\n",
    "print(\"Primera fecha val:\", val[\"date\"].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5adc3e",
   "metadata": {},
   "source": [
    "## 3. Selección de features a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e2a61",
   "metadata": {},
   "source": [
    "Seleccionamos las columnas que realmente creemos que pueden aportar información al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4f0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"warehouse\", \"availability\", \"price_log\", \"orders_log\", \"max_discount\",\n",
    "    \"L1_category_name_en\", \"L2_category_name_en\", \"L3_category_name_en\", \"L4_category_name_en\",\n",
    "    \"holiday\", \"shops_closed\", \"winter_school_holidays\", \"school_holidays\", \n",
    "    \"year\", \"day_of_week\", \"day_of_year\", \"year_month\", \"cos_day\", \"sin_day\", \n",
    "    \"sales_rolling_7d\", \"sales_rolling_28d\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fafd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"sales_log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb68ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=True)\n",
    "\n",
    "train_dicts = X_train.to_dict(orient=\"records\")\n",
    "X_train_encoded = dv.fit_transform(train_dicts).astype(\"float32\")\n",
    "\n",
    "val_dicts = X_val.to_dict(orient=\"records\")\n",
    "X_val_encoded = dv.transform(val_dicts).astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09957b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train[target].values\n",
    "y_val = X_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c223287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run rf_baseline at: http://localhost:5000/#/experiments/4/runs/31c0ace0aa6e4bd1b3bbbe760ce50088\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/4\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Path 'outputs/rf_model' already exists and is not empty",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     31\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33moutputs/rf_model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Log artifacts manually\u001b[39;00m\n\u001b[32m     35\u001b[39m mlflow.log_artifacts(model_path, artifact_path=\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/forecasting/lib/python3.12/site-packages/mlflow/sklearn/__init__.py:245\u001b[39m, in \u001b[36msave_model\u001b[39m\u001b[34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m serialization_format \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_SERIALIZATION_FORMATS:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    238\u001b[39m         message=(\n\u001b[32m    239\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized serialization format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mserialization_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Please specify one\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    242\u001b[39m         error_code=INVALID_PARAMETER_VALUE,\n\u001b[32m    243\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[43m_validate_and_prepare_target_save_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m code_path_subdir = _validate_and_copy_code_paths(code_paths, path)\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mlflow_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/forecasting/lib/python3.12/site-packages/mlflow/utils/model_utils.py:271\u001b[39m, in \u001b[36m_validate_and_prepare_target_save_path\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_and_prepare_target_save_path\u001b[39m(path):\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(os.scandir(path)):\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    272\u001b[39m             message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPath \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m already exists and is not empty\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    273\u001b[39m             error_code=RESOURCE_ALREADY_EXISTS,\n\u001b[32m    274\u001b[39m         )\n\u001b[32m    276\u001b[39m     os.makedirs(path, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mMlflowException\u001b[39m: Path 'outputs/rf_model' already exists and is not empty"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"retail_nb_experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"rf_baseline\"):\n",
    "    # Modelo\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=10,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train_encoded, y_train)\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = rf.predict(X_val_encoded)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    # Log params, metrics, model\n",
    "    mlflow.log_param(\"n_estimators\", 10)\n",
    "    mlflow.log_param(\"max_depth\", 10)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Save model locally\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    model_path = \"outputs/rf_model\"\n",
    "    mlflow.sklearn.save_model(rf, model_path)\n",
    "\n",
    "    # Log artifacts manually\n",
    "    mlflow.log_artifacts(model_path, artifact_path=\"model\")\n",
    "\n",
    "print(f\"RMSE on validation: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cac1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttraining's rmse: 0.0304644\tvalid_1's rmse: 0.0356869\n",
      "[100]\ttraining's rmse: 0.0202031\tvalid_1's rmse: 0.0242816\n",
      "[150]\ttraining's rmse: 0.018392\tvalid_1's rmse: 0.0226674\n",
      "[200]\ttraining's rmse: 0.0174329\tvalid_1's rmse: 0.0222356\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's rmse: 0.0174329\tvalid_1's rmse: 0.0222356\n",
      "🏃 View run lgbm_baseline at: http://localhost:5000/#/experiments/4/runs/2e5ee8ec799d46aa817580cb3a0e1d95\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/4\n",
      "✅ RMSE on validation: 0.0222\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lightgbm as lgb\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm_baseline\"):\n",
    "    train_set = lgb.Dataset(X_train_encoded, label=y_train)\n",
    "    val_set = lgb.Dataset(X_val_encoded, label=y_val, reference=train_set)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": 31,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"verbose\": -1,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=20),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ]\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=200,\n",
    "        valid_sets=[train_set, val_set],\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_val_encoded, num_iteration=model.best_iteration)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    # Log params y métricas\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Guardar modelo local y loguearlo como artifact\n",
    "    os.makedirs(\"outputs_lgbm\", exist_ok=True)\n",
    "    model.save_model(\"outputs_lgbm/lgbm_model.txt\")\n",
    "    mlflow.log_artifact(\"outputs_lgbm/lgbm_model.txt\", artifact_path=\"lgbm_model\")\n",
    "\n",
    "print(f\"✅ RMSE on validation: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d233bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.05897\tval-rmse:1.05428\n",
      "[50]\ttrain-rmse:0.02231\tval-rmse:0.02522\n",
      "[100]\ttrain-rmse:0.01851\tval-rmse:0.02165\n",
      "[150]\ttrain-rmse:0.01769\tval-rmse:0.02121\n",
      "[200]\ttrain-rmse:0.01696\tval-rmse:0.02098\n",
      "[249]\ttrain-rmse:0.01633\tval-rmse:0.02096\n",
      "🏃 View run xgb_baseline at: http://localhost:5000/#/experiments/4/runs/24d62de0af7a430caf81d0663c7ab980\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/4\n",
      "✅ RMSE on validation: 0.0209\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"retail_nb_experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgb_baseline\"):\n",
    "    # Convertir a DMatrix (estructura interna de XGBoost)\n",
    "    dtrain = xgb.DMatrix(X_train_encoded, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val_encoded, label=y_val)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"max_depth\": 6,\n",
    "        \"eta\": 0.1,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "    evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "    # Entrenar con early stopping\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=500,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=50\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = model.predict(dval, iteration_range=(0, model.best_iteration))\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    # Log params y métricas\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Guardar modelo local y subirlo a MLflow\n",
    "    os.makedirs(\"outputs_xgb\", exist_ok=True)\n",
    "    model.save_model(\"outputs_xgb/xgb_model.json\")\n",
    "    mlflow.log_artifact(\"outputs_xgb/xgb_model.json\", artifact_path=\"xgb_model\")\n",
    "\n",
    "print(f\"✅ RMSE on validation: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b71f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"retail_nb_experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"catboost_baseline\"):\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=300,\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        loss_function=\"RMSE\",\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        thread_count=-1\n",
    "    )\n",
    "    # Nota: usamos X_train_encoded / X_val_encoded (ya vectorizados)\n",
    "    model.fit(X_train_encoded, y_train, eval_set=(X_val_encoded, y_val), use_best_model=True)\n",
    "\n",
    "    y_pred = model.predict(X_val_encoded)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_params({\n",
    "        \"iterations\": 300,\n",
    "        \"depth\": 8,\n",
    "        \"learning_rate\": 0.08,\n",
    "        \"loss_function\": \"RMSE\"\n",
    "    })\n",
    "\n",
    "    os.makedirs(\"outputs_cat\", exist_ok=True)\n",
    "    model.save_model(\"outputs_cat/cat_model.cbm\")  # formato nativo CatBoost\n",
    "    mlflow.log_artifact(\"outputs_cat/cat_model.cbm\", artifact_path=\"catboost_model\")\n",
    "\n",
    "print(f\"✅ CatBoost RMSE on validation: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782960ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
